# 操作系统

## 计算机系统概述

### 操作系统的基本概念

#### 操作系统的概念

操作系统是指控制和管理整个计算机系统的硬件和软件资源，合理地组织、调度计算机的工作与资源的分配，进而为用户和其他软件提供方便接口与环境的程序集合。操作系统是计算机系统中最基本的系统软件。

#### 操作系统的特征

1. 并发

   并发是指两个或多个事件在同一时间间隔内发生，操作系统的并发性是指计算机系统中同时存在多个运行的程序，因此它们具有处理和调度多个程序同时执行的能力。注意同一时间间隔（并发）和同一时刻（并行）的区别。在多道程序环境下，一段时间内，宏观上有多道程序在同时执行，而在每个时刻，单处理机环境下实际仅能有一道程序执行，因此微观上这些程序仍是分时交替执行的。

2. 共享

   共享是指系统中的资源可供内存中多个并发执行的进程共同使用。共享可分为互斥共享方式和同时访问方式，其中同时访问方式中的“同时”通常是宏观上的，而在微观上，可能还是“分时”的。

3. 虚拟

   虚拟是指把一个物理上的实体变为若干逻辑上的对应物。物理实体是实的，即实际存在的；而后者是虚的，是用户感觉上的事物。操作系统中利用了多种虚拟技术（时分复用和空分复用）来实现虚拟处理器、虚拟内存和虚拟外部设备等。

4. 异步

   多道程序环境允许多个程序并发执行，但由于资源有限，进程的执行并不是一贯到底的，而是走走停停的，它以不可预知的速度向前推进，这就是进程的异步性。异步性使得操作系统运行在一种随机的环境下，可能导致进程产生与时间有关的错误。然而，只要运行环境相同，操作系统就须保证多次运行进程后都能获得相同的结果。

#### 操作系统的目标和功能

1. 操作系统作为计算机系统资源的管理者

   1. 处理机管理

      在多道程序环境下，处理机的分配和运行都以进程（或线程）为基本单位，因而对处理机的管理可归结为对进程的管理。进程何时创建、何时撤销、如何管理、如何避免冲突、合理共享是进程管理最主要的任务。进程管理的主要功能包括进程控制、进程同步、进程通信、死锁处理、处理机调度等。

   2. 存储器管理

      存储器管理主要包括内存分配与回收、地址映射、内存保护与共享和内存扩充等功能。

   3. 文件管理

      文件管理包括文件存储空间的管理、目录管理及文件读写管理和保护等。

   4. 设备管理

      设备管理的主要任务是完成用户的I/O请求，主要包括缓冲管理、设备分配、设备处理和虚拟设备等功能。

2. 操作系统作为用户与计算机硬件系统之间的接口

   1. 命令接口

      按照作业控制方式的不同，可将命令接口分为联机命令接口（交互式命令接口）和脱机命令接口（批处理命令接口）。

   2. 程序接口

      程序接口由一组系统调用（也称广义指令）组成。用户通过在程序中使用这些系统调用来请求操作系统为其提供服务，如使用各种外部设备、申请分配和回收内存等。

3. 操作系统实现了对计算机资源的扩充

   没有任何软件支持的计算机称为裸机，它仅构成计算机系统的物质基础，而实际呈现在用户面前的计算机系统是经过若干层软件改造的计算机。裸机在最里层，其外面是操作系统。操作系统所提供的资源管理功能和方便用户的各种服务功能，将裸机改造成功能更强、使用更方便的机器。因此，我们通常把覆盖了软件的机器称为扩充机器或虚拟机。

### *操作系统的发展历程

#### 手工操作阶段（此阶段无操作系统）

#### 批处理阶段（操作系统开始出现）

#### 分时操作系统

#### 实时操作系统

#### 网络操作系统和分布式操作系统

#### 个人计算机操作系统

### 操作系统运行环境

#### 处理器运行模式

计算机系统中，通常CPU执行两种不同性质的程序：一种是操作系统内核程序；另一种是用户程序。内核程序是用户程序的管理者，内核程序要执行一些特权指令，而用户程序出于安全考虑不能执行这些指令。在具体实现上，将CPU的运行模式划分为用户态（目态）和核心态（管态、内核态），这种状态被记录在CPU的程序状态字寄存器（PSW）中。用户程序运行在用户态，操作系统内核程序运行在核心态。

在操作系统中引入核心态和用户态这两种工作状态后，就需要考虑这两种状态之间如何切换：

1. 核心态 -> 用户态

   这是由内核程序主动引发的。在合适的时候，内核程序会用一条特权指令把PSW的标志位设置为“用户态”，操作系统主动让出CPU的使用权。

2. 用户态 -> 核心态

   这是由中断和异常引发的，硬件自动完成CPU状态的转变，操作系统强行夺回CPU的使用权。

#### 中断和异常

1. 中断和异常的定义

   - 中断(Interruption)：也称外中断，是指来自CPU执行指令外部的事件，与当前执行的指令无关。如I/O结束中断、时钟中断。
   - 异常(Exception)：也称内中断，是指来自CPU执行指令内部的事件，与当前执行的指令有关。如特权指令、地址越界、运算溢出、缺页、陷入指令等。异常不能被屏蔽，一旦出现，就应立即处理。

2. 中断和异常的分类

   - 外中断可分为可屏蔽中断和不可屏蔽中断。可屏蔽中断在CPU处于关中断状态下不能中断程序；不可屏蔽中断可以随时中断程序，通常是紧急的硬件故障。
   - 异常可分为故障、自陷和终止。故障(Fault)通常是由指令执行引起的异常，如非法操作码、缺页故障、除数为0、运算溢出等。自陷(Trap)是一种事先安排的“异常”事件，用于在用户态下调用操作系统的内核程序，如陷入指令。终止(Abort)是指出现了使得CPU无法继续执行的硬件故障，如控制器出错、存储器校验错等。故障异常和自陷异常属于软件中断（程序性异常），终止异常和外中断属于硬件中断。

   ![image-20230508163748137](https://raw.githubusercontent.com/Cukoo-Li/typora-photos/main/2023/05/upgit_20230508_1683535068.png)

3. 中断和异常的处理过程

   当CPU在执行用户程序的第i条指令时检测到一个异常或中断，则CPU打断当前的用户程序，然后转到相应的中断或异常处理程序去执行。若中断或异常处理程序能够解决相应的问题，则在中断或异常处理程序的最后，CPU通过执行中断或异常返回指令，回到被打断的用户程序的第i条指令或第i+1条指令继续执行；若中断或异常处理程序发现是不可恢复的知名错误，则终止用户程序。通常情况下，对中断和异常的具体处理过程由操作系统（和驱动程序）完成。

#### 系统调用

系统调用是指用户在程序中调用操作系统所提供的一些子功能，系统调用可视为特殊的公共子程序。系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，凡是与资源有关的操作（如存储分配、I/O传输及文件管理等），都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。通常，一个操作系统提供的系统调用命令有几十条乃至上百条之多。这些系统调用可大致分为：

- 设备管理
- 文件管理
- 进程管理
- 进程通信
- 内存管理

系统调用的处理需要由操作系统内核程序负责完成，要运行在核心态。用户程序可以执行陷入指令（访管指令、trap指令）来发起系统调用，请求操作系统提供服务。因此，系统调用程序也算是一种异常处理程序。

### *操作系统结构

### 操作系统引导

操作系统是一种程序，程序以数据的形式存放在硬盘中，而硬盘通常分为多个区，一台计算机中又有多个或多种外部存储设备。操作系统引导是指计算机利用CPU运行特定程序，通过程序识别硬盘，识别硬盘分区，识别硬盘分区上的操作系统，最后通过程序启动操作系统。

常见的操作系统引导过程如下：

1. 激活CPU

   激活的CPU读取ROM中的boot程序，将指令寄存器置为BIOS（基本输入/输出系统）的第一条指令，即开始执行BIOS的指令。

2. 硬件自检

   启动BIOS程序后，先进行硬件自检，检查硬件是否出现故障。如有故障，主板会发出不同含义的蜂鸣，启动终止；如无故障，屏幕会显示CPU、内存、硬盘等信息。

3. 加载带有操作系统的硬盘

   硬件自检后，BIOS开始读取Boot Sequence（通过CMOS里保存的启动顺序，或者通过与用户交互的方式），把控制权交给启动顺序排在第一位的存储设备，然后CPU将该存储设备引导扇区的内容加载到内存中。

4. 加载主引导记录MBR

   硬盘以特定的标识符区分引导硬盘和非引导硬盘。如果发现一个存储设备不是可引导硬盘，就检查下一个存储设备。如无其他启动设备，就会死机。主引导记录MBR的作用是告诉CPU去硬盘的哪个主分区去找操作系统。

5. 扫描硬盘分区表，并加载硬盘活动分区

   MBR包含硬盘分区表，硬盘分区表以特定的标识符区分活动分区和非活动分区。主引导记录扫描硬盘分区表，进而识别含有操作系统的硬盘分区（活动分区）。找到硬盘活动分区后，开始加载硬盘活动分区，将控制权交给活动分区。

6. 加载分区引导记录PBR

   读取活动分区的第一个扇区，这个扇区称为分区引导记录(PBR)，其作用是寻找并激活分区根目录下用于引导操作系统的程序（启动管理器）。

7. 加载启动管理器

   分区引导记录搜索活动分区中的启动管理器，加载启动管理器

8. 加载操作系统

### *虚拟机

## 进程与线程

### 进程与线程

#### 进程的概念和特征

1. 进程的概念

   - 进程是程序的一次执行过程，是系统进行资源分配和调度的一个独立单位
   - 进程控制块(PCB)是系统用于描述进程的基本情况和运行状态的一种数据结构，是进程存在的唯一标志
   - 进程实体（进程映像）由PCB、程序段、数据段三部分构成
   - 所谓创建进程和撤销进程，实质上是创建和撤销进程实体中的PCB
   - 进程映像是静态的，进程是动态的

2. 进程的特征

   进程是由多道程序的并发执行而引出的，它和程序是两个既然不同的概念。进程的基本特征是对比单个程序的顺序执行提出的，也是对进程管理提出的基本要求。

   1. 动态性

      进程是程序的一次执行，它有着创建、活动、暂停、终止等过程，具有一定的生命周期，是动态地产生、变化和消亡的。

   2. 并发性

      指多个程序实体同存于内存中，能在一段时间内同时运行。引入进程的目的就是使进程能和其他进程并发执行。

   3. 独立性

      指进程实体是一个独立运行、独立获得资源和独立接受调度的基本单位。

   4. 异步性

      由于进程的相互制约，使得进程按各自独立的、不可预知的速度向前推进。异步性会导致执行结果的不可再现性，为此在操作系统中必须配置相应的进程同步机制。

#### 进程的状态和转换

通常进程有以下5种状态，前3种是进程的基本状态

1. 运行态

   进程正在处理机上运行。在单处理机种，每个时刻只有一个进程处于运行态。

2. 就绪态

   进程获得了除处理机外的一切所需资源，一旦得到处理机，便可立即运行。系统通常将处于就绪态的进程排成一个就绪队列。

3. 阻塞态（等待态）

   进程正在等待某一事件而暂停运行，如等待某资源（不包括处理机）为可用或等待输入/输出完成。即使处理机空闲，该进程也不能运行。系统通常将处于阻塞态的进程也排一个队列，甚至根据阻塞原因的不同，设置多个阻塞队列。

4. 创建态

   进程正在被创建，尚未转到就绪态。创建进程需要多个步骤：首先申请一个空白PCB，并向PCB种填写用于控制和管理进程的信息；然后为该进程分配运行时所必须的资源；最后把该进程转入就绪态并插入就绪队列。但是，如果进程所需的资源尚不能得到满足，如内存不足，则创建工作尚未完成，进程此时所处的状态称为创建态。

5. 结束态

   进程正在从系统消失，可能是进程正常结束或由于其他原因退出运行。进程需要结束运行时，系统首先将其设置为结束态，然后进一步处理资源释放和回收等工作。

![image-20230511154855805](https://raw.githubusercontent.com/Cukoo-Li/typora-photos/main/2023/05/upgit_20230511_1683791336.png)

#### 进程的组织

为了方便进程的调度和管理，需要将各进程的PCB用适当的方法组织起来。目前，常用的组织方式有链接方式和索引方式两种。

1. 链接方式：将同一状态的PCB链接成一个队列，不同状态对应不同队列
2. 索引方式：将同一状态的进程组织在一个索引表种，索引表的表项指向相应的PCB

#### 进程控制

- 进程控制的主要功能是实现进程状态的转换
- 一般把进程控制用的程序段称为原语
- 按照功能的不同，可将原语分为创建原语、终止原语、阻塞原语、唤醒原语
- 无论是哪个进程控制原语，要做的无非三类事情：更新PCB中的信息，更新PCB所在队列、分配或回收资源

#### 线程和多线程模型

1. 线程的基本概念

   - 线程最直接的理解就是“轻量级的进程”，它是一个基本的CPU执行单元，也是程序执行流的最小单元
   - 线程是进程中的一个实体，是被系统调度的基本单位
   - 线程自己不拥有系统资源，但它可以与同属于一个进程的其他线程共享进程所拥有的全部资源
   - 一个线程可以创建和撤销另 一个线程，同一进程中的多个线程之间可以并发执行
   - 线程也有就绪、阻塞和运行三种基本状态
   - 引入线程后，进程只作为除CPU外的系统资源的分配单元，而线程作为处理机的分配单元

2. 线程与进程的比较

   1. 调度。

      在传统的操作系统中，进程是调度的基本单位。每次调度都需要进行上下文切换，开销较大。引入线程后，线程变成调度的基本单位，在同一进程中线程切换的开销远小于进程切换。

   2. 并发性

      引入线程后，不仅进程之间可以并发执行，而且一个进程中的多个线程之间也可以并发执行，操作系统具有更好的并发性。

   3. 拥有资源

      进程是系统中拥有资源的资本单位，而线程不拥有资源，但线程可以访问其隶属进程的系统资源。

   4. 独立性

      每个进程都有独立的地址空间和资源，同一进程中的不同线程共享进程的地址空间和资源。

   5. 系统开销

      在创建、撤销、调度/切换、通信方面，线程的开销比进程小得多。

   6. 支持多处理机系统

      对于传统单线程进程，不管有多少处理机，进程只能运行在一个处理机上。对于多线程进程，可以将进程中的多个线程分配到多个处理机上执行。

3. 线程的实现方式

   线程的实现可以分为两类：用户级线程和内核级线程

   1. 用户级线程

      在用户级线程中，有关线程管理的所有工作都由应用程序在用户空间中完成，内核意识不到线程的存在。应用程序可以通过线程库设计成多线程程序。通常，应用程序从单线程开始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库创建一个在相同进程中运行的新线程。

      - 优点：①线程切换不需要转换到内核空间，节省了模式切换的开销；②调度算法可以是进程专用的，不同的进程可以根据自身的需要，对自己的线程选择不同的调度算法；③用户级线程的实现与操作系统平台无关，对线程管理的代码是属于用户程序的一部分
      - 缺点：①当线程执行一个系统调用时，不仅该线程被阻塞，而且进程内的所有线程都被阻塞；②不能发挥多处理机的优势，内核每次分配给进程的仅有一个CPU，因此进程中仅有一个线程能执行

   2. 内核级线程

      在内核级线程中，有关线程管理的所有工作在内核空间内实现。内核空间为每个内核级线程设置一个线程控制块，内核根据该控制块感知某线程的存在，并对其加以控制。

      - 优点：①能发挥多处理机的优势，内核能同时调度同一进程中的多个线程并行执行；②如果进程中的一个线程被阻塞，其他线程不受影响；③内核支持线程具有很小的数据结构和堆栈，线程切换比较快、开销小；④内核本身也可以采用多线程技术，可以提高系统的执行速度和效率
      - 缺点：同一进程中的线程切换，需要从用户态转到核心态，系统开销较大

   3. 组合方式

      将用户级线程和内核级线程组合可以集两者之所长

      ![image-20230511221302158](https://raw.githubusercontent.com/Cukoo-Li/typora-photos/main/2023/05/upgit_20230511_1683814382.png)

   4. 多线程模型

      有些系统同时支持用户线程和内核线程，由于用户级线程二号内核级线程的连接方式不同，从而形成了三种不同的多线程模型。

      ![image-20230511221622012](https://raw.githubusercontent.com/Cukoo-Li/typora-photos/main/2023/05/upgit_20230511_1683814582.png)

### 处理机调度

#### 调度的概念

处理机调度是对处理机进行分配，即按照一定的算法选择一个进程并将处理机分配给它运行，以实现进程并发地执行。

一个作业从提交开始直到完成，往往要经历以下三级调度：

- 高级调度（作业调度）：按照某种规则，从后备队列中选择合适的作业将其从外存调入内存，并为其创建进程

- 中级调度（内存调度）：按照某种规则，从挂起队列中选择合适的进程将其数据从外存调回内存，并放在就绪队列

- 低级调度（进程调度）：按照某种规则，从就绪队列中选择一个进程为其分配处理机

三级调度有以下特点：

- 作业调度为进程活动做准备，进程调度使进程正常活动起来
- 某些进程因系统内存不足而被挂起（调回外存），中级调度负责在合适的时候把被挂起的进程重新调入内存，并修改其状态为就绪态
- 进程调度是最基本的，不可或缺
- 作业调度次数少，中级调度次数略多，进程调度频率最高

#### 调度算法的评价指标

- CPU利用率：CPU有效工作时间与总工作时间之比
- 系统吞吐量：单位时间内CPU完成作业的数量
- 周转时间：作业提交到作业完成所经历的时间
- 等待时间：进程处于等处理机的时间之和
- 响应时间：用户提交请求到系统首次产生响应所用的时间

#### 调度的实现

1. 调度程序（调度器）

   在操作系统中，用于调度和分派CPU的组件称为调度程序。它通常由三部分组成：

   1. 排队器

      将系统中的所有就绪进程按照一定的策略排成一个或多个队列，以便于调度程序选择

   2. 分派器

      依据调度程序所选的进程，将其从就绪队列中取出，将CPU分配给新进程

   3. 上下文切换器

      切换CPU现场信息

2. 调度的时机、切换与过程

   不能进行进程调度与切换的情况有以下几种：

   1. 处理中断的过程中
   2. 进程在操作系统内核临界区中
   3. 原子操作

   应该进行进程调度与切换的情况如下：

   1. 发生引起调度的条件且当前进程无法继续运行下去时，可以马上进行调度与切换
   2. 中断处理结束或自陷处理结束后，返回被中断进程的用户态程序执行现场前，若置上请 调度标志，即可马上进行进程调度与切换

3. 进程调度方式

   当某个进程正在处理机上执行，若有某个更为重要或紧迫的进程需要处理，即有优先权更高的进程进入就绪队列，如何分配处理机？

   1. 非抢占调度方式（非剥夺方式）

      仍然让正在执行的进程进程继续执行，直到该进程运行结束或进入阻塞态时，才把处理机分配给这个更为重要或紧迫的进程。

   2. 抢占调度方式（剥夺方式）

      允许调度程序根据某种规则去暂停正在执行的进程，将处理机分配给这个更为重要或紧迫的进程。

#### *典型的调度算法

1. 先来先服务(FCFS)调度算法
2. 短作业优先(SJF)调度算法
3. 优先级调度算法
4. 高响应比优先调度算法
5. 时间片轮转调度算法
6. 多级队列调度算法
7. 多级反馈队列调度算法

### 同步与互斥

#### 同步与互斥的基本概念

1. 临界资源

   一次仅允许一个进程使用的资源称为临界资源。

   可以将访问临界资源的代码分为4个部分：

   1. 进入区。检查是否可以进入临界区，若能进入，则设置正在访问临界区的标志
   2. 临界区。进程中真正访问/操作临界资源的那段代码，又称临界段
   3. 退出区。将正在访问临界区的标志清除
   4. 剩余区。代码的其余部分

2. 同步（（直接制约关系））

   在多道程序系统中，多个进程以不可预知的速度并发执行。当两个或多个进程需要合作时，往往需要在某些位置上协调它们的工作次序，这样就产生了一种制约关系。

3. 互斥（间接制约关系）

   当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。

   同步机制应遵循以下准则：

   1. 空闲让进
   2. 忙则等待
   3. 有限等待
   4. 让权等待

#### 实现临界区互斥的基本方法

1. 软件实现方法

   1. 单标志法

      - 通俗理解：谦让

      - 设置一个公用整型变量turn，用于指示被允许进入临界区的进程编号

      - 违背“空闲让进”：两个进程必须交替进入临界区，若某个进程不再进入临界区，则另一个进程也无法进入临界区

      - ```cpp
        // P0进程						// P1进程
        while (turn != 0);				while (turn != 1);
        critical section;				critical section;
        turn = 1;					   turn = 0;
        remainder section;				remainder section;
        ```

   2. 双标志先检查法

      - 通俗理解：先看看是否空闲

      - 在每个进程访问临界区之前，先检查临界资源是否正在被访问

      - 为此，设置一个数据flag[i]，如第i个元素值为false，表示Pi进程没进入临界区

      - 违背“忙则等待”：多道程序并发执行时，有可能会同时进入临界区

      - ```cpp
        // P0进程						// P1进程
        while (flag[1]);			    while (flag[0]);
        flag[0] = true;				    flag[1] = true;
        critical section;			    critical section;
        flag[0] = false;			    flag[1] = false;
        remainder section;				remainder section;
        ```

   3. 双标志后检查法

      - 与双标志先检查法类似，区别在于检查和上锁的次序不同

      - 违背“空闲让进”：多道程序并发时，有可能都进入不了临界区

      - ```cpp
        // P0进程						// P1进程
        flag[0] = true;				    flag[1] = true;
        while (flag[1]);			    while (flag[0]);
        critical section;			    critical section;
        flag[0] = false;			    flag[1] = false;
        remainder section;				remainder section;
        ```

      - 两种双标志法的问题在于：检查和上锁不能一气呵成，导致了bug的出现

   4. Peterson算法

      - 通俗理解：先看看是否空闲，若空闲，就谦让对方先进去

      - 结合了双标志法和单标志法

      - 好像没什么缺点

      - ```cpp
        // P0进程						// P1进程
        flag[0] = true;				    flag[1] = true;
        turn = 1;					   turn = 0
        while (flag[1] && turn == 1);	  while (flag[0] && turn == 0);
        critical section;			    critical section;
        flag[0] = false;			    flag[1] = false;
        remainder section;				remainder section;
        ```

2. 硬件实现方法

   1. 中断屏蔽方法

      - 中断屏蔽过程中CPU不能进行进程切换，因此能保证当前进程顺利执行完临界区代码，从而达到互斥的目的
      - 只适用于单处理机系统

   2. 硬件指令方法

      由硬件逻辑直接实现，不会被中断，是原子操作。

      - TestAndSet指令：功能是读出指定标志后把该标志设置为真，其实就是填补了双标志法缺陷

        ```cpp
        while TestAndSet(&lock);
        critical section;
        lock = false;
        remainder section;
        ```

      - Swap指令：交换两个字（字节）的内容

        ```cpp
        key = true;
        while (key != false)
            Swap(&lock, key);
        critical section;
        lock = false;
        remainder section;
        ```

#### 互斥锁

解决临界区最简单的工具就是互斥锁(mutex lock)。一个进程在进入临界区时应获得锁；在退出临界区时释放锁。函数acquire()获得锁，函数release()释放锁。

每个互斥锁有一个布尔变量available，表示锁是否可用。如果锁是可用的，调用acqiure()会成功，且锁不再可用。当一个进程试图获取不可用的锁时，会被阻塞，直到锁被释放。

```cpp
acquire() {
    while(!available)
        ;				// 忙等待
    available = false;	  // 获得锁
}
release() {
    available = true;	  // 释放锁
}
```

acquire()和release()必须是原子操作，因此互斥锁通常采用硬件机制来实现。

互斥锁的主要缺点是忙等待，当有一个进程在临界区中，任何其他进程在进入临界区时必须连续循环调用acquire()。当多个进程共享一个CPU时，就浪费了CPU周期。因此，互斥锁通常用于多处理机系统，一个线程可以在一个处理机上等待，不影响其他线程的执行。

#### 信号量

信号量机制是一种功能较强的机制，可以用来解决互斥与同步问题，它只能被两个标准的原语wait(S)和signal(S)访问，也可以记为“P操作”和“V操作”。

1. 整型信号量

   整型信号量被定义为一个用于表示资源数目的整型量S，与普通整型变量不同的是，它只能执行初始化、wait和signal操作。

   ```cpp
   wait(S) {
       while (S <= 0);
       S = S - 1;
   }
   signal(S) {
       S = S + 1;
   }
   ```

   在整型信号量机制中的wait操作，只要信号量S<=0，就会不断地测试。因此，该机制为遵循“让权等待”准则，而是让进程“忙等”。

2. 记录型信号量

   记录型信号量机制是一种不存在“忙等”现象的进程同步机制。除了需要一个用于代表资源数目的整型变量value外，还需要一个进程链表L，用于链接所有等待该资源的进程。记录型信号量得名于采用了记录型的数据结构。记录型信号量可描述为：

   ```cpp
   typedef struct {
       int value;
       struct process *L
   } semaphore;
   ```

   相应wait(S)和signal(S)操作如下：

   ```cpp
   void wait(semaphore S) {
       --S.value;
       if (S.value < 0) {
           add this process to S.L;
           block(S.L);  // 阻塞该进程
       }
   }
   
   void signal(semaphore S) {
       ++S.value;
       if(S.value <= 0) {
           remove a process P from S.L;
           wakeup(P);  // 唤醒P进程
       }
   }
   ```

3. 利用信号量实现互斥

   在互斥问题中，PV操作要紧夹使用互斥资源的那个行为，中间不能有其他冗余代码

   ```cpp
   semaphore S = 1;	  // 初始化信号量
   P1() {
       ...
       P(S);			 // 准备开始访问临界资源，加锁
       进程P1的临界区；
       V(S)；			// 访问结束，解锁
       ...
   }
   P2() {
       ...
       P(S);			 // 准备开始访问临界资源，加锁
       进程P2的临界区；
       V(S)；			// 访问结束，解锁
       ...
   }
   ```

4. 利用信号量实现同步

   ```cpp
   semaphore S = 0;    // 初始化信号量
   P1() {
       ...
       前操作;
       V(S);           // 告诉进程P2，前操作已经完成
       ...
   }
   P2() {
       ...
       P(S);		   // 检查前操作是否运行完成
       后操作;
       ...
   }
   ```

   前V后P：在前操作之后进行V操作，在后操作之前进行P操作

5. 利用信号量实现前驱关系

   为每一对关系分别设置信号量，遵循前V后P的规律编写代码即可

   ![image-20230514232923889](https://raw.githubusercontent.com/Cukoo-Li/typora-photos/main/2023/05/upgit_20230514_1684078163.png)

#### 管程

管程就是对为实现同步与互斥而进行的各种复杂操作的一种封装，使得程序员只需要调用相应的接口即可实现同步与互斥。

#### 经典同步问题

1. 生产者-消费者问题

   - 问题描述：

     一组生产者进程和一组消费者进程共享一个初始为空、大小为n的缓冲区，只有当缓冲区没满时，生产者才能把消息放入缓冲区，否则必须等待；只有缓冲区不为空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源，它只允许一个生产者放入消息，或一个消费者从中取出消息

   - 问题分析：

     - 对缓冲区的互斥访问比较简单，只需要让设置一个互斥信号量mutex，然后让每个进程进入临界区前后分别进行P操作和V操作即可
     - 这里有两种同步关系：①缓冲区中需要先有消息，消费者才能取出消息，为此设置一个信号量full，初值为0；②缓冲区中需要先有空位，生产者才能放入消息，为此设置一个信号量empty，初值为n

   - 代码实现：

     ```cpp
     semaphore mutex = 1;
     semaphore full = 0;
     semaphore empty = n;
     producer() {
         while(true) {
             produce an item;
             P(empty);		// 申请获取空缓冲区单元
             P(mutex);
             add an item to buffer;
             P(mutex);
             V(full);		// 缓冲区单元数+1
         }
     }
     consumer() {
         while(true) {
             P(full);		// 申请获取非空缓冲区单元
             P(mutex);
             remove an item in buffer;
             V(mutex);
             V(empty);		// 空缓冲区单元数+1
         }
     }
     ```

   - 问题描述：

     桌上有一个盘子，每次只能向其中放入一个水果。爸爸专向盘子中放苹果，妈妈专向盘子中放句子，儿子专等吃盘子中的句子，女儿专等吃盘子中的苹果。只有盘子为空时，爸爸或妈妈才可以向盘子中放一个水果；仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出

   - 问题分析：

     - 互斥访问，设置一个互斥信号量mutex，然后让每个进程进入临界区前后分别进行P操作和V操作即可
     - 这里有三种同步关系：①只有当盘子为空时，爸爸或妈妈才可以向盘子中放一个水果。注意，盘子为空这个事件既可以由儿子吃苹果触发，又可以由女儿吃橘子触发。为此设置一个信号量plate，初值为1,表示有空位，允许放入。儿子或女儿吃完后，要V(plate)，爸爸或妈妈放入前，要P(plate)；②只有当盘子中有苹果时，儿子才能吃苹果。为此设置一个信号量apple，初值为0，表示没有苹果。爸爸放入苹果后，要V(apple)，儿子吃苹果前，要P(apple);③女儿跟妈妈之间也有类似的同步关系

2. 读者-写者问题（较复杂）

   - 问题描述：

     有读者和写者两组并发进程，共享一个文件，当两个或以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读进程或写进程）同时访问共享数据时则可能导致数据不一致的错误。因此要求：①允许多个读者可以同时对文件执行读操作；②只允许一个写者往文件中写信息；③任一写者在完成写操作之前不允许其他读者或写者工作；④写者执行写操作前，应让已有的读者和写者全部退出

   - 问题分析：

     - 读者和写者是互斥的，写者和写者也是互斥的，而读者和读者不存在互斥问题。设置信号量rw用于互斥访问，设置count变量用于记录当前的读者数量。在读者进程中，当且仅当count==0时，才需要对rw进行PV操作
     - 在读者进程对count变量进行读写时，如果发生进程切换，会出现问题。解决办法是设置互斥信号量mutex，用对mutex的PV操作将读写count变量的代码部分包起来，从而使其“一气呵成”（其实只是阻止了其他读者进程的干预）
     - 为了防止写进程“饿死”，设置信号量w，在读进程和写进程中各增加一对PV操作，可以实现先来先服务的效果

   - 代码实现：

     ```cpp
     int count = 0;			// 用于记录当前的读者数量
     semaphore mutex = 1;	 // 用于保护读写count变量时的互斥
     semaphore rw = 1;		// 用于保护读者和写者互斥地访问文件
     semaphore w = 1;		// 与上述信号量一起，实现排队
     writer() {
         while(true) {
             P(w);
             P(rw);
             writing;
             V(rw);
             V(w);
         }
     }
     reader() {
         while(true) {
             P(w);
             P(mutex);
             if (count == 0)
                 P(rw);
             ++count;
             V(mutex);
             V(w);
             reading;
             P(mutex);
             --count;
             if (count == 0)
                 V(rw);
             V(mutex);
         }
     }
     ```

3. 哲学家进餐问题

   - 问题描述：

     一张圆桌边上坐着5名哲学家，每两名哲学家之间的桌上摆一根筷子，两根筷子中间是一碗米饭，如图2.12所示。哲学家们倾注毕生精力用于思考和进餐，哲学家在思考时，并不影响他人。只有当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根地拿起）。若筷子已在他人手上，则需要等待。饥饿的哲学家只有同时拿到了两根筷子才可以开始进餐，进餐完毕后，放下筷子继续思考

4. 吸烟者问题

   - 问题描述：

     假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟并抽掉它，但要卷起并抽掉一支烟，抽烟者需要有三种材料：烟草、纸和胶水。三个抽烟者中，第一个拥有烟草，第二个拥有纸，第三个拥有胶水。供应者进程无限地提供三种材料，供应者每次将两种材料放到桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者一个信号告诉已完成，此时供应者就会将另外两种材料放到桌上，如此重复（让三个抽烟者轮流地抽烟）

   - 问题分析：

     - 互斥访问，设置一个互斥信号量mutex，然后让每个进程进入临界区前后分别进行P操作和V操作即可
     - 对于三个抽烟者而言，必须先有对应材料，才能卷烟并抽掉，为此分别设置三个信号量offer1,offer2,offer3；对于供应者而言，必须先有任一一个抽烟者的给出的完成信号，才能把材料放桌子上，为此设置一个信号量finish


### 死锁

#### 死锁的概念

1. 死锁的定义

   所谓死锁，是指多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。

2. 死锁产生的必要条件

   产生死锁必须同时满足以下4个条件，只要其中任意一个条件不成立，死锁就不会发生

   1. 互斥条件：进程要求对所分配的资源进行排他性使用
   2. 不剥夺条件：进程所获得的资源在未使用完之前，不能被其他进程强行夺走，只能由获得该资源的进程自己主动释放
   3. 请求并保持条件：进程对自身本来拥有的资源保持不放，并请求其他资源
   4. 循环等待条件：存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求

3. 死锁的处理策略

   1. 死锁预防

      设置某些限制条件，破坏产生死锁的4个必要条件中的一个或几个

   2. 避免死锁

      在资源的动态分配过程中，用某种方法防止系统进入不安全状态

   3. 死锁的检测及解除

      不采取任何限制性措施，允许发生死锁。通过系统的检测机制及时地检测出死锁的发生，然后采取某种措施解除死锁

#### 死锁预防

缺陷很多，pass!

#### 避免死锁

1. 系统安全状态

   所谓安全状态，是指系统能按某种进程推进顺序(P~1~,P~2~,...,P~n~)为每个进程P~i~分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可以顺序完成。此时成P~1~,P~2~,...,P~n~为安全序列。若系统无法找到一个安全序列，则称系统处于不安全状态

2. 银行家算法

   ①进程运行之前先声明对各种资源的最大需求量；②当进程在执行过程中继续申请资源时，先检查是否超出了最大需求量；③检查现有的资源数能否满足该进程的请求；④试着把资源分配给该进程，考察此时系统是否仍处于安全状态

   1. 数据结构描述

      - 可利用资源向量Available：含有m个元素的数组，其中每个元素代表一类可用的资源数目
      - 最大需求矩阵Max：n×m矩阵，定义系统中n个进程中的每个进程对m类资源的最大需求
      - 分配矩阵Allocation：n×m矩阵，定义系统中每类资源当前已分配给每个进程的资源数
      - 需求矩阵Need：n×m矩阵，表示每个进程接下来最多还需要多少资源

   2. 银行家算法描述

      设Request~i~是进程P~i~的请求向量，Request~i~[j]=K表示进程P~i~需要j类资源K个。当P~i~发出资源请求后，系统按下述步骤进行检查：

      1. 若Request~i~[j]<=Need[i,j]，则转向步骤2；否则认为出错，因为它所需要的资源数已超过它所声明的最大值
      2. 若Request~i~[j]<=Available[j]，则转向步骤3；否则，表示尚无足够资源，P~i~须等待
      3. 系统试着把资源分配给进程P~i~，并更新Available、Allocation、Need
      4. 系统执行安全性算法，检查此此资源分配后，系统是否处于安全状态。若安全，才正式将资源分配给进程P~i~，以完成本次分配；否则，将本次的试探性分配作废，恢复原来的资源分配状态，让进程P~i~等待

   3. 安全性算法

      设置工作向量Work，有m个元素，表示系统中的剩余可用资源数目。在执行安全性算法开始时，Work=Available

      1. 初始时安全序列为空
      2. 从Need矩阵中找出符合以下条件的行：该行对应的进程不在安全序列中，而且该行小于等于Work向量，找到后，把对应的进程加入安全序列；若找不到，则执行步骤4
      3. 进程P~i~进入安全序列后，可顺序执行，直至完成，并释放分配给它的资源，因此应执行Work = Work + Allocation[i]，返回步骤2
      4. 若此时所有进程都在安全序列中，则系统处于安全状态，否则系统处于不安全状态

#### 死锁的检测及解除

1. 资源分配图

   用圆圈代表一个进程，用框代表一类资源，从进程到资源的有向边称为请求边，从资源到进程的边称为分配边

2. 死锁定理

   如果资源分配图是不可完全简化的，则说明发生了死锁

3. 死锁解除

   资源剥夺法、撤销进程法、进程回退法

## 内存管理

### 内存管理概念

#### 内存管理的基本原理和要求

内存管理的主要功能：

- 内存空间的分配与回收
- 地址转换
- 内存空间的扩充
- 内存共享
- 内存保护

1. 程序的链接与装入

   将用户源程序变为可在内存中执行的程序，通常需要以下几个步骤：

   - 编译。由编译程序将用户源代码编译成若干目标模块
   - 链接。由链接程序将编译后形成的一组目标模块以及它们所需的库函数链接在一起，形成一个完整的装入模块
   - 装入。由装入程序将装入模块装入内存运行

   程序的链接有三种方式：

   1. 静态链接

      在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的装配模块，以后不再拆开。

   2. 装入时动态链接

      在装入内存时，对各目标模块进行边装入边链接。

   3. 运行时动态链接

      对于某些目标模块的链接，是在程序执行过程中需要该目标模块时才进行的。

   将装入模块装入内存时，同样有以下三种方式：

   1. 绝对装入

      目标程序中的逻辑地址就是绝对地址，不需要进行地址转换，仅适用于单道程序环境。

   2. 静态重定位

      重定位是指在装入时对目标程序中的指令和数据地址进行修改的过程，地址转换是在进程装入时一次完成的。

   3. 动态重定位

      装入时不立即把逻辑地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行（通过重定位寄存器实现）。

2. 逻辑地址与物理地址

   - 逻辑地址是程序员看得到、使用得到的地址
   - 物理地址是数据在主存中的实际地址
   - 当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址，这个过程称为地址重定位

3. 进程的内存映像

   不同于存放在硬盘上的可执行程序文件，当一个程序调入内存运行时，就构成了进程的内存映像。

   一个进程的内存映像一般有几个要素：

   - 代码段：即程序的二进制代码，代码段是只读的，可以被多个进程共享
   - 数据段：即程序运行时加工处理的对象，包括全局变量和静态变量
   - 进程控制块(PCB)：存放在系统区。操作系统通过PCB来控制和管理进程
   - 堆：用来存放动态分配的变量。通过调用malloc函数动态地向高地址分配空间
   - 栈：用来实现函数调用。从用户空间的最大地址往低地址方向增长

   代码段和数据段在程序调入内存时就指定了大小，而堆和栈不一样。当调用像malloc和free这样的C标准库函数时，堆可以在运行时动态地扩展和收缩。用户栈在程序运行时也可以动态地扩展和收缩，每次调用一个函数，栈就会增长；从一个函数返回时，栈就会收缩。

4. 内存保护

   内存保护是指要确保每个进程都有一个单独的内存空间，进程之间互不影响。

   内存保护可采取两种方法：

   1. 在CPU中设置一对上、下限寄存器，存放用户作业在主存中的上限和下限地址，每当CPU要访问一个地址时，判断有无越界。
   2. 采用重定位寄存器（基址寄存器）和界地址寄存器（限长寄存器）来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址的最大值。内存管理机构动态地将逻辑地址与界地址寄存器进行比较，若未发生越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。

5. 内存共享

   并不是所有的进程内存空间都适合共享，只有那些只读的区域才可以共享。

6. 内存分配与回收

   存储管理方式随着操作系统的发展而发展。在操作系统由单道向多道发展时，存储管理方式便由单一连续分配发展为固定分区分配。为了能更好地适应不同大小的程序要求，又从固定分区分配发展到动态分区分配。为了更好地提高内存的利用率，进而从连续分配方式发展到离散分配方式————页式存储管理。引入分段存储管理的目的，主要是为了满足用户在编程和使用方面的要求，其中某些要求是其他几种存储管理方式难以满足的。

#### *覆盖与交换

1. 覆盖

   把用户程序的内存空间分为一个固定区和若干覆盖区，将经常活跃的部分放在固定区，将那些即将要访问的部分放入覆盖区，其余部分放在外存，在需要时再调入覆盖区，替换覆盖区原有的内容。

   覆盖技术对用户和程序员不透明，增加了编码的难度，已经成为了历史。

2. 交换

   把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这一过程又称换出；把准备号竞争CPU运行的程序从辅存移到内存，这一过程又称换入。第2章介绍的中级调度采用的就是交换技术。

#### 连续分配管理方式

连续分配方式是指为一个用户程序分配一个连续的内存空间，主要包括单一连续分配、固定分区分配和动态分区分配

1. 单一连续分配

   内存分为系统区和用户区，系统区仅供操作系统使用，通常在低地址部分；在用户区内存中，仅有一道用户程序，即整个内存的用户空间由该程序独占。

2. 固定分区分配

   将用户内存空间划分成若干固定大小的区域，每个分区只装入一道作业。其中又分为两种类型：分区大小相等、分区大小不等。为便于内存分配，通常将分区按大小排队，并为之建立一张分区说明表，其中各表项包括每个分区的起始地址、大小和状态。当有用户程序要装入时，就检索该表，以找到合适的分区给予分配并更改其状态为“已分配”；未找到合适分区时，则拒绝为该程序分配内存。

3. 动态分区分配

   在进程装入内存时，根据进程的实际需要，动态地为之分配内存，使其分区大小正好适合进程的需要。因此，系统中分区的大小和数目是可变的。与固定分区分配类似，在动态分区分配中也会设置一张空闲分区表（链）。

   动态分区在开始时是很好的，但随着时间的推移，内存中会产生越来越多的外部碎片。外部碎片的问题可以通过紧凑技术来解决，即操作系统不时地对进程进行移动和整理，这需要动态重定位寄存器的支持，且相对费时。紧凑的过程实际上类似于windows系统中的磁盘碎片整理程序，只不过后者是对外存空间的紧凑。

#### 基本分页存储管理

固定分区会产生内部碎片，动态分区会产生外部碎片，这两种技术对内存的利用率都比较低。 们希望内存的使用能尽量避免碎片的产生，这就引入了分页的思想：

- 把主存空间划分为大小相等且固定的块，作为主存的基本单元
- 每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个申请主存中的块空间

1. 分页存储的几个基本概念

   1. 页面和页面大小

      - 进程中的块称为页或页面(Page)
      - 内存中的块称为页框或页帧(Page Frame)

   2. 地址结构

      - 逻辑地址结构包含两部分：页号P、页内偏移量W
      - 页号的位数反映页数，页内地址的位数反映页面大小

   3. 页表

      为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，它记录页面在内存中对应的物理块号（页号是隐含的，不占用存储空间），页表一般存放在内存中。因此，页表的作用是实现从页号到物理块号的地址映射

2. 基本地址变换机构

   在系统中通常设置一个页表寄存器(PTR)，存放页表在内存的起始地址F和页表长度M。进程未上处理机执行时，页表始址和页表长度存放在进程的PCB中，当进程被调度执行时，才将页表始址和页表长度装入页表寄存器中。

   设页面大小为L，逻辑地址A到物理地址E的变换过程如下：

   1. 计算页号P和页内偏移量W （P = A / L, W = A % L）
   2. 比较页号P和页表长度M，若P ≥ M，则产生地址越界中断
   3. 页表中页号P对应的页表项地址 = 页表始址F + 页号P × 页表项长度，取出该页表项内容b，即为物理块号
   4. 物理地址E = b × L + W

3. 具有快表的地址变换机构

   快表是一种高速缓冲存储器，又称相联存储器(TLB)，用来存放当前访问的若干页表项（含页号）

4. 两级页表

   单级页表存在的问题：

   1. 所有的页表项必须连续存放，页表过大时需要很大的连续空间
   2. 在一段时间内并非所有页面都用得到，没必要让整个页表常驻内存

   为此，进一步延伸页表映射的思想，就可以得到二级分页

   - 为查询方便，顶级页表最多只能有一个页面
   - 逻辑地址空间结构：一级页号、二级页号、页内偏移量
   - 在进程执行时，只需要将这一页的上一级页表调入内存即可，进程的页表和进程本身的页面可在后面的执行中再调入内存

#### 基本分段存储管理

分页管理方式是从计算机的角度考虑设计的，目的是提高内存的利用率。分页通过硬件机制实现，对用户完全透明。分段管理方式的提出则考虑了用户和程序元，以满足方便编程、信息保护和共享、动态增长及动态链接等多方面的需要。

1. 分段

   - 分段管理方式按照用户进程中的自然段划分逻辑空间，其逻辑地址由段号S与段内偏移量W两部分组成

   - 若段号为16位，段内偏移量为16位，则一个作业最多有2^16^段，最大段长为2^16^B

   - 在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量和必须由用户显式提供，在高级语言中，这个工作由编译程序完成

2. 段表

   每个段表项对应进程的一段，段表项记录该段在内存中的始址和长度，段号是隐含的

3. 地址变换机构

   段表寄存器中记录了段表始址F和段表长度M

   1. 从逻辑地址A中分离出段号S和段内偏移量W
   2. 比较段号S和段表长度M的大小，若S>=M，则产生越界中断，否则继续执行
   3. 段表中段号S对应的段表项地址 = 段表始址F + 段号S × 段表项长度，取出该段表项记录的段长C。若段内偏移量W>=C，则产生越界中断，否则继续执行
   4. 取出段表项中记录的始址，计算E=b+W，用得到的物理地址E去访问内存

4. 段的共享

   在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现的

#### 段页式管理

分页存储管理能有效地提高内存利用率，而分段存储管理能反应程序的逻辑结构并有利于段的共享和保护。将这两种存储管理方法结合起来，便形成了段页式存储管理方式。

在段页式系统中，作业的地址空间首先被分成若干逻辑段，每段都有自己的段号，然后将每段分成若干大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干和页面大小相同的存储块，对内存的分配以存储块为单位。

在段页式系统中，逻辑地址分为三部分：段号、页号和页内偏移量，页号的位数决定了一个段最多能分成多少页。

在段页式系统中，系统为每个进程建立一张段表，每个分段有一张页表。段表项中包括段号（隐含的）、页表长度和页表始址，页表项中包括页号和块号。此外，系统中还有一个段表寄存器，指出作业的段表始址和段表长度。

在进行地址变换时，首先通过段表查到页表始址，然后通过页表找到页帧号，最后形成物理地址。进行一次访问实际需要三次访存。

### 虚拟内存管理

#### 虚拟内存的基本概念

1. 传统存储管理方式的特征

   - 一次性：作业必须一次性全部装入内存后，才能开始运行
   - 驻留性：作业被装入内存后，就一直驻留在内存中，其任何部分都不会被换出，直至作业运行结束

   许多在程序运行中不用或暂时不用的程序（数据）占据了大量的内存空间，而一些需要运行的作业又无法装入运行。

2. 局部性原理

   - 时间局部性
   - 空间局部性

3. 虚拟存储器的定义和特征

   1. 虚拟存储器的定义

      基于局部性原理，在程序装入时，仅须将程序当前要运行的少数页面或段先装入内存，其余部分暂留在外存，便可启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不用的内容换出到外存，从而腾出内存空间。这样，系统好像为用户提供了一个比实际内存容量大得多的存储器，称为虚拟存储器。

   2. 虚拟存储器的特征

      1. 多次性：允许作业被分成多次调入内存运行
      2. 对换性：允许将那些暂不使用的程序和数据从内存调至外存的对换区，待需要时再将它们从外存调至内存
      3. 虚拟性：从逻辑上扩充了内存的容量

4. 虚拟内存技术的实现

   虚拟内存的实现需要建立在离散分配的内存管理方式的基础上，有三种实现方式：

   - 请求分页存储管理
   - 请求分段存储管理
   - 请求段页式存储管理

   不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面：
   
   - 一定容量的内存和外存
   - 页表机制（或段表机制），作为主要的数据结构
   - 中断机构，当用户程序要访问的部分尚未调入内存时，则产生中断
   - 地址变换机构，逻辑地址到物理地址的变换
   
   #### 请求分页管理方式
   
   请求分页系统建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。
   
   1. 页表机制
   
      请求页表项中增加了4个字段：
   
      - 状态位P。用于指示该页是否调入内存，供程序访问时参考
      - 访问字段A。用于记录本页最近的访问情况，供置换算法换出页面时参考
      - 修改位M。标识该页在调入内存后是否被修改过，以确定页面置换时是否写回外存
      - 外存地址。用于指出该页在外存的地址，通常是物理块号，供调入该页时参考
   
   2. 缺页中断机构
   
      在请求分页系统中，每当所要访问的页面不在内存中时，便产生一个缺页中断，请求操作系统将所缺的页面调入内存。此时应将缺页的进程阻塞（调页完成后唤醒）。若内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中相应的页表项；若内存中没有空闲块，则要淘汰某页（若被淘汰页在内存期间被修改过，则要将其写回内存）。
   
      缺页中断作为中断，同样要经历诸如保护CPU现场、分析中断原因、转入缺页中断处理程序、恢复CPU现场等步骤。但与一般的中断相比，它有以下两个明显的区别：
   
      - 在指令执行期间而非一条指令执行完后产生和处理中断信号，属于内中断/异常
      - 一条指令在执行期间，可能产生多次缺页中断
   
   3. 地址变换机构
   
      在进行地址变换时，先检索快表：
   
      - 若找到要访问的页，则修改页表项中的访问位（写指令还需要重置修改位），然后利用页表项中给出的物理块号和页内地址形成物理地址
      - 若未找到该页的页表项，则应到内存中去查找页表，再比对页表项中的状态位P，看该页是否已调入内存。若页面已调入，则将该页的页表写入块表，若快表已满，则需采用某种算法替换。若页面未调入，则产生缺页中断，请求从外存把该页调入内存
   
      ![image-20230614192751925](https://raw.githubusercontent.com/Cukoo-Li/typora-photos/main/2023/06/upgit_20230614_1686742072.png)
   
   #### 页框分配
   
   #### 页面置换算法
   
   1. 最佳(OPT)置换算法
   
      OPT算法选择淘汰在最长时间内不再被访问的页面，以便保证获得最低的缺页率。然而，这个算法实现的前提是页面号引用串已知，但这是无法预知的，因此该算法无法实现。
   
   2. 先进先出(FIFO)置换算法
   
      FIFO算法实现简单，但忽略没有考虑进程实际运行时的规律，可能产生所分配的物理块数增大而缺页故障数不减反增的异常现象（Belady异常）。
   
   3. 最近最久未使用（LRU）置换算法
   
      LRU算法选择淘汰最近最长时间未访问过的页面。该算法为每个页面设置一个访问字段，用来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。
   
   4. 时钟(CLOCK)置换算法
   
      LRU算法的性能接近OPT算法，但实现起来的开销较大。因此，操作系统的设计者尝试了很多算法，试图用比较小的开销接近LRU算法的性能，这类算法都是CLOCK算法的变体。
   
      1. 简单的CLOCK置换算法
         - 为每帧设置一位访问位，当某页首次被装入或被访问时，其访问位被置为1
         - 将内存中的所有页面视为一个循环队列，并有一个替换指针与之相关联，当某一页被替换时，该指针被设置指向被替换页面的下一页。依次循环检查每一个页面的访问位，若为0，就选择该页换出；若为1，则将它置为0
         - 又称最近未用(NRU)算法
      2. 改进型CLOCK置换算法
         - 除了考虑页面使用情况外，还考虑了置换代价，为此设置一位修改位
         - 由访问位和修改位M可以组合成四种类型的页面：
           1. A=0, M=0: 最近未被访问且未被修改，是最佳淘汰页
           2. A=0, M=1: 最近未被访问，但已被修改，不是很好的淘汰页
           3. A=1, M=0: 最近已被访问，但未被修改，可能再被访问
           4. A=1, M=1: 最近已被访问且已被修改，可能再被访问
         - 在选择页面换出时，优先考虑既未使用过又未修改过的页面
